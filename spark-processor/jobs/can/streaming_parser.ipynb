{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e617b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import MapType\n",
    "import cantools\n",
    "import json\n",
    "from pbspark import MessageConverter\n",
    "from canbus_test_pb2 import CANBusMessage\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75297f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "jarsPackages = \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1,com.datastax.spark:spark-cassandra-connector_2.12:3.2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64903be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .appName('Spark Structured Streaming from Sensor EV-BUS') \\\n",
    "                    .config(\"spark.jars.packages\", jarsPackages) \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbc = cantools.database.load_file('./j1939.dbc')\n",
    "dbc.add_dbc_file('iso.dbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa119782",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MessageConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91897ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseProtoKafka(df, proto):\n",
    "    # Parsed Protobuf encryption\n",
    "    parsedData = df.withColumn('firstparsed', mc.from_protobuf('value', proto)) \\\n",
    "        .withColumn('topic', expr('headers')[0]['value'].cast('string')) \\\n",
    "        .withColumn('bus_id', expr('headers')[2]['value'].cast('string')) \\\n",
    "        .selectExpr('topic','bus_id', 'firstparsed.*') \\\n",
    "        .withColumn('secondparsed', mc.from_protobuf('canId', proto)) \\\n",
    "        .selectExpr('topic','bus_id','secondparsed.*') \\\n",
    "        .withColumnRenamed('canId','can_id') \\\n",
    "        .withColumn('timestamp', to_timestamp(col('timestamp') / 1000))\n",
    "    \n",
    "    return parsedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "LONG_MESSAGE = {}\n",
    "def parse_can_message(ID_HEX,DLC,DATA_HEX_STR):\n",
    "        try:\n",
    "            ID_HEX = int.from_bytes(ID_HEX, \"big\")\n",
    "        except:\n",
    "            pass\n",
    "        DATA_LEN = int(DLC)\n",
    "        PRIORITY = ID_HEX & (0b00011100 << 24)\n",
    "        RESERVED = ID_HEX & (0b00000010 << 24)\n",
    "        DATA_PAGE = ID_HEX & (0b00000001 << 24)\n",
    "        PDU_FORMAT = ID_HEX & (0b11111111 << 16)\n",
    "        PDU_SPECIFIC = ID_HEX & (0b11111111 << 8)\n",
    "        SOURCE_ADDRESS = ID_HEX & (0b11111111 << 0)\n",
    "        \n",
    "        PGN = RESERVED | DATA_PAGE | PDU_FORMAT | PDU_SPECIFIC\n",
    "        DBC_ID = PRIORITY | PGN | 0xFE\n",
    "        try:\n",
    "            currMsg = dbc.get_message_by_frame_id(DBC_ID)\n",
    "            try:\n",
    "                outdata = dbc.decode_message(DBC_ID,DATA_HEX_STR,decode_choices=True)\n",
    "                if(outdata):\n",
    "                    for key in outdata.keys():\n",
    "                        if not isinstance(outdata[key], int) and not isinstance(outdata[key], float) and not isinstance(outdata[key], str):\n",
    "                            outdata[key] = str(outdata[key])\n",
    "                outdata[\"MessageName\"] = currMsg.name\n",
    "                json_data = json.dumps(outdata)\n",
    "                return str(json_data)\n",
    "            except:\n",
    "                if currMsg.frame_id in LONG_MESSAGE.keys():\n",
    "                    LONG_MESSAGE[currMsg.frame_id] = f\"{LONG_MESSAGE[currMsg.frame_id]}{DATA_HEX_STR}\"\n",
    "                    try:\n",
    "                        outdata = dbc.decode_message(DBC_ID,LONG_MESSAGE[currMsg.frame_id],decode_choices=True)\n",
    "                        if(outdata):\n",
    "                            for key in outdata.keys():\n",
    "                                if not isinstance(outdata[key], int) and not isinstance(outdata[key], float) and not isinstance(outdata[key], str):\n",
    "                                    outdata[key] = str(outdata[key])\n",
    "                        outdata[\"MessageName\"] = currMsg.name\n",
    "                        del LONG_MESSAGE[currMsg.frame_id]\n",
    "                        json_data = json.dumps(outdata)\n",
    "                        return str(json_data)\n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                    LONG_MESSAGE[currMsg.frame_id] = DATA_HEX_STR\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafkaDF = spark.readStream \\\n",
    "      .format(\"kafka\") \\\n",
    "      .option(\"kafka.bootstrap.servers\", \"10.252.62.70:9092\") \\\n",
    "      .option(\"subscribe\", 'canbus_test') \\\n",
    "      .option(\"includeHeaders\", \"true\") \\\n",
    "      .option('startingOffsets', 'latest') \\\n",
    "      .load() \\\n",
    "      .selectExpr(\"headers\",\"CAST(key AS STRING)\", \"value\",\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_proto_kafka = parseProtoKafka(kafkaDF,CANBusMessage)\n",
    "# parserCan = udf(lambda m,n,o: parse_can_message(m,n,o))\n",
    "parserCan = udf(lambda m,n,o: parse_can_message(m,n,o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "parserValue = parse_proto_kafka.withColumn(\"parser_value\", parserCan('can_id','dlc','data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = parserValue.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option('truncate', False) \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0413517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38d2af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
